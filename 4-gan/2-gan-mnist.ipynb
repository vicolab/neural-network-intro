{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This area sets up the Jupyter environment.\n",
    "Please do not modify anything in this cell.\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Add project to PYTHONPATH for future use\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# Import miscellaneous modules\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Set CSS styling\n",
    "with open('../admin/custom.css', 'r') as f:\n",
    "    style = \"\"\"<style>\\n{}\\n</style>\"\"\".format(f.read())\n",
    "    display(HTML(style))\n",
    "\n",
    "# Plots will be show inside the notebook\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import problem_unittests as tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks 2\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This is a continuation of the previous notebook, where we learned the gist of what a generative adversarial network (GAN) is and how to learn a 1-d multimodal distribution. Please refer back to the last notebook if you are unsure about what a GAN is.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: MNIST Dataset\n",
    "\n",
    "In this notebook we will use a GAN to generate samples coming from the familiar MNIST dataset.\n",
    "\n",
    "We will start loading by our data.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>In the following snippet of code we will:</strong>\n",
    "  <ul>\n",
    "    <li>Load data from MNIST </li>\n",
    "    <li>Merge the training and test set</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.datasets import mnist\n",
    "\n",
    "import admin.tools as tools\n",
    "\n",
    "\n",
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_data = np.concatenate((X_train, X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pre-Processing\n",
    "\n",
    "As we have done previously with MNIST, the first thing we will be doing is normalisation. However, this time we will normalise the 8-bit images from [0, 255] to [-1, 1].\n",
    "\n",
    "Previous research with GANs indicates that this normalisation yields better results ([reference paper](https://arxiv.org/abs/1406.2661)).\n",
    "\n",
    "\n",
    "### Task I:  Implement an Image Normalisation Function\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "**Task**: Implement a function that normalises the images to the interval [-1,1].\n",
    "<ul>\n",
    "  <li>Inputs are integers in the interval [0,255]</li>\n",
    "  <li>Outputs should be floats in the interval [-1,1]</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    \"\"\"\n",
    "    Create Matrix Y\n",
    "    :param images: Np tensor with N x R x C x CH.\n",
    "    Where R = Number of rows in a image\n",
    "    Where C = Number of cols in a image\n",
    "    Where CH = Number of channles in a image\n",
    "    \n",
    "    :return: images with its values normalized to [-1,1].\n",
    "    \"\"\"\n",
    "    images = None\n",
    "    return images\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Test normalisation function and normalise the data if it passes\n",
    "tests.test_normalize_images(normalize_images)\n",
    "X_data = normalize_images(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in a previous notebook we will add an extra dimension to our greyscale images.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>In the following code snippet we will:</strong>\n",
    "<ul>\n",
    "  <li>Transform `X_data` from $(28,28)$ to $(28,28,1)$</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = np.expand_dims(X_data, axis=-1)\n",
    "\n",
    "print('Shape of X_data {}'.format(X_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task II: Implement a Generator Network\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Task:</strong> :\n",
    "<ul>\n",
    "  <li>Make a network that accepts inputs where the shape is defined by `zdim` $\\rightarrow$ `shape=(z_dim,)`</li>\n",
    "  <li>The number of outputs of your network need to be defined as `nb_outputs`</li>\n",
    "  <li>Reshape the final layer to be in the shape of `output_shape`</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "* Since the data lies in the range [-1,1] try using the 'tanh' as the final activation function.\n",
    "\n",
    "Keras references: [Reshape()](https://keras.io/layers/core/#reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import some useful keras libraries\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "\n",
    "def generator(z_dim, nb_outputs, ouput_shape):\n",
    "    \n",
    "    # Define the input_noise as a function of Input()\n",
    "    latent_var = None\n",
    "\n",
    "    # Insert the desired amount of layers for your network\n",
    "    x = None\n",
    "    \n",
    "    # Map you latest layer to n_outputs\n",
    "    x = None\n",
    "    \n",
    "    # Reshape you data\n",
    "    x = Reshape(ouput_shape)(x)\n",
    "\n",
    "    model = Model(inputs=latent_var, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a generative network using the function you just made.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong>In the following code snippet we will:</strong>\n",
    "<ul>\n",
    "  <li>Define the number of dimensions of the latent vector $\\mathbf{z}$</li>\n",
    "  <li>Find out the shape of a sample of data</li>\n",
    "  <li>Compute numbers of dimensions in a sample of data</li>\n",
    "  <li>Create the network using your function</li>\n",
    "  <li>Display a summary of your generator network</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dimension of the latent vector\n",
    "z_dim = 100\n",
    "\n",
    "# Dimension of our sample\n",
    "sample_dimentions = (28, 28, 1)\n",
    "\n",
    "# Calculate the number of dimensions in a sample\n",
    "n_dimensions=1\n",
    "for x in list(sample_dimentions):\n",
    "    n_dimensions *= x\n",
    "\n",
    "print('A sample of data has shape {} composed of {} dimension(s)'.format(sample_dimentions, n_dimensions))\n",
    "\n",
    "# Create the generative network\n",
    "G = generator(z_dim, n_dimensions, sample_dimentions)\n",
    "\n",
    "# We recommend the followin optimiser\n",
    "g_optim = keras.optimizers.adam(lr=0.002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile network\n",
    "G.compile (loss='binary_crossentropy', optimizer=g_optim)\n",
    "\n",
    "# Network Summary\n",
    "G.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task III: Implement a Discriminative Network\n",
    "\n",
    "The discriminator network is a simple binary classifier where the output indicates the probability of the input data being real or fake.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>Task:</strong>\n",
    "<ul>\n",
    "  <li> Create a network where the input shape is `input_shape`\n",
    "  <li> We recomend reshaping your network  just after input. This way you can have a vector with shape `(None, nb_inputs)`</li>\n",
    "  <li> Implement a simple network that can classify data</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Keras references: [Reshape()](https://keras.io/layers/core/#reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(input_shape, nb_inputs):\n",
    "    # Define the network input to have input_shape shape\n",
    "    input_x = None\n",
    "    \n",
    "    # Reshape your input\n",
    "    x = None\n",
    "    \n",
    "    # Implement the rest of you classifier\n",
    "    x = None\n",
    "    \n",
    "    probabilities = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_x, outputs=probabilities)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a discriminator network using the function you just made.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>In the following code snippet we will:</strong>\n",
    "<ul>\n",
    "  <li>Create the network using your function</li>\n",
    "  <li>Display a summary of your generator network</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We already computed the shape and number of dimensions in a data sample\n",
    "print('The data has shape {} composed of {} dimension(s)'.format(sample_dimentions, n_dimensions))\n",
    "\n",
    "# Discriminative Network\n",
    "D = discriminator(sample_dimentions,n_dimensions)\n",
    "\n",
    "# Recommended optimiser\n",
    "d_optim = keras.optimizers.adam(lr=0.002, beta_1=0.5, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile Network\n",
    "D.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "\n",
    "# Network summary\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the GAN together\n",
    "\n",
    "In the following code we will put the generator and discriminator together so we can train our  adversarial model.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>In the following code snippet we will:</strong>\n",
    "<ul>\n",
    "  <li>Use the generator and discriminator to construct a GAN</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import   Sequential\n",
    "\n",
    "\n",
    "def build(generator, discriminator):\n",
    "    \"\"\"Build a base model for a Generative Adversarial Networks.\n",
    "    Parameters\n",
    "    ----------\n",
    "    generator : keras.engine.training.Model\n",
    "        A keras model built either with keras.models ( Model, or Sequential ).\n",
    "        This is the model that generates the data for the Generative Adversarial networks.\n",
    "    Discriminator : keras.engine.training.Model\n",
    "        A keras model built either with keras.models ( Model, or Sequential ).\n",
    "        This is the model that is a binary classifier for REAL/GENERATED data.\n",
    "    Returns\n",
    "    -------\n",
    "    (keras.engine.training.Model)\n",
    "        It returns a Sequential Keras Model by connecting a Generator model to a\n",
    "        Discriminator model.  [ generator-->discriminator]\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create GAN\n",
    "G_plus_D = build(G, D)\n",
    "G_plus_D.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
    "D.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task IV: Define Hyperparameters\n",
    "\n",
    "Please define the following hyper-parameters to train your GAN.\n",
    "<br>\n",
    "<div class=\"alert alert-success\">\n",
    "  <strong>Task:</strong> Please define the following hyperparameters to train your GAN:\n",
    "  <ul>\n",
    "  <li> Batch size</li>\n",
    "  <li>Number of training epochs</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong>In the following code snippet we will:</strong>\n",
    "<ul>\n",
    "  <li>Train the constructed GAN</li>\n",
    "  <li>Live plot the generated data</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Figure for live plot\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "# Allocate space for noise variable\n",
    "z = np.zeros((BATCH_SIZE, z_dim))\n",
    "\n",
    "# n_bathces\n",
    "number_of_batches = int(X_data.shape[0] / BATCH_SIZE)\n",
    "\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    for index in range(number_of_batches):\n",
    "        \n",
    "        # Sample minimibath m=BATCH_SIZE from data generating distribution\n",
    "        # in other words :\n",
    "        # Grab a batch of the real data\n",
    "        data_batch = X_data[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "        \n",
    "        # Sample minibatch of m= BATCH_SIZE noise samples\n",
    "        # in other words, we sample from a uniform distribution\n",
    "        z = np.random.uniform(-1, 1, (BATCH_SIZE,z_dim))\n",
    "\n",
    "        # Sample minibatch m=BATCH_SIZE from data generating distribution Pdata\n",
    "        # in ohter words\n",
    "        # Use genrator to create new fake samples\n",
    "        generated_batch = G.predict(z, verbose=0)\n",
    "\n",
    "        # Update/Train discriminator D\n",
    "        X = np.concatenate((data_batch, generated_batch))\n",
    "        y = [1] * BATCH_SIZE + [0.0] * BATCH_SIZE\n",
    "\n",
    "        d_loss = D.train_on_batch(X, y)\n",
    "\n",
    "        # Sample minibatch of m= BATCH_SIZE noise samples\n",
    "        # in other words, we sample from a uniform distribution\n",
    "        z = np.random.uniform(-1, 1, (BATCH_SIZE,z_dim))\n",
    "\n",
    "        #Update Generator while not updating discriminator\n",
    "        D.trainable = False\n",
    "        # to do gradient ascent we just flip the labels ...\n",
    "        g_loss = G_plus_D.train_on_batch(z, [1] * BATCH_SIZE)\n",
    "        D.trainable = True\n",
    "        \n",
    "        # Plot data every 10 mini batches\n",
    "        if index % 10 == 0:\n",
    "            ax.clear() \n",
    "\n",
    "            # Histogram of generated data\n",
    "            image =tools.combine_images(X)\n",
    "\n",
    "            image = image*127.5+127.5\n",
    "            ax.imshow(image.astype(np.uint8))\n",
    "            fig.canvas.draw()\n",
    "            time.sleep(0.01)\n",
    "\n",
    "\n",
    "    # End of epoch ....\n",
    "    print(\"epoch %d : g_loss : %f  | d_loss : %f\" % (epoch, g_loss,  d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
